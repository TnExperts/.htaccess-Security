# Defining custom error document so that all restrictions are routed to a HTML page which minimizes the resource impact:
ErrorDocument 403 bad-bots.html

# Disable directory indexing:
Options -Indexes 

# Twarting XSS attacks
Options +FollowSymLinks
RewriteEngine On
RewriteCond %{QUERY_STRING} base64_encode.*\(.*\) [OR]
RewriteCond %{QUERY_STRING} (\<|%3C).*script.*(\>|%3E) [NC,OR]
RewriteCond %{QUERY_STRING} (\<|%3C).*iframe.*(\>|%3E) [NC,OR]
RewriteCond %{QUERY_STRING} GLOBALS(=|\[|\%[0-9A-Z]{0,2}) [OR]
RewriteCond %{QUERY_STRING} _REQUEST(=|\[|\%[0-9A-Z]{0,2})
RewriteRule ^(.*)$ index_error.php [F,L]
RewriteCond %{REQUEST_METHOD} ^(TRACE|TRACK)
RewriteRule .* - [F]

# Block bad bots & scrapers using their user-agents
#
# blocking content harvesters and site copiers 
SetEnvIfNoCase User-Agent .*wget.* bad_bot
SetEnvIfNoCase User-Agent .*curl.* bad_bot
SetEnvIfNoCase User-Agent .*libwww-perl.* bad_bot
SetEnvIfNoCase User-Agent .*WinHttp.* bad_bot
SetEnvIfNoCase User-Agent .*okhttp.* bad_bot
SetEnvIfNoCase User-Agent .*python.* bad_bot
SetEnvIfNoCase User-Agent .*java.* bad_bot
SetEnvIfNoCase User-Agent .*WebReaper.* bad_bot
SetEnvIfNoCase User-Agent .*WebSauger.* bad_bot
SetEnvIfNoCase User-Agent ".*Website\ eXtractor.*" bad_bot
SetEnvIfNoCase User-Agent ".*Website\ Quester.*" bad_bot
SetEnvIfNoCase User-Agent .*Webster.* bad_bot
SetEnvIfNoCase User-Agent .*WebStripper.* bad_bot
SetEnvIfNoCase User-Agent .*WebWhacker.* bad_bot
SetEnvIfNoCase User-Agent .*WebZIP.* bad_bot
SetEnvIfNoCase User-Agent .*Whacker.* bad_bot
SetEnvIfNoCase User-Agent .*BatchFTP.* bad_bot
SetEnvIfNoCase User-Agent .*HTTrack.* bad_bot
SetEnvIfNoCase User-Agent .*Harvest.* bad_bot
SetEnvIfNoCase User-Agent .*Collector.* bad_bot
SetEnvIfNoCase User-Agent .*Copier.* bad_bot
SetEnvIfNoCase User-Agent .*Extractor.* bad_bot
SetEnvIfNoCase User-Agent .*lftp.* bad_bot
SetEnvIfNoCase User-Agent ".*libWeb\/clsHTTP.*" bad_bot
SetEnvIfNoCase User-Agent .*Mirror.* bad_bot
SetEnvIfNoCase User-Agent ".*Net\ Vampire.*" bad_bot
SetEnvIfNoCase User-Agent ".*Offline\ Explorer.*" bad_bot
SetEnvIfNoCase User-Agent ".*Offline\ Navigator.*" bad_bot

# blocking vulnerability scanners
SetEnvIfNoCase User-Agent .*Acunetix.* bad_bot
SetEnvIfNoCase User-Agent .*FHscan.* bad_bot

# blocking aggressive chinese search engine
SetEnvIfNoCase User-Agent .*Baidu.* bad_bot
 
# blocking aggressive russian search engine
SetEnvIfNoCase User-Agent .*Yandex.* bad_bot

# blocking aggressive downloader scripts
SetEnvIfNoCase User-Agent ".*Download\ Demon.*" bad_bot
SetEnvIfNoCase User-Agent ".*Download\ Devil.*" bad_bot
SetEnvIfNoCase User-Agent ".*Download\ Wonder.*" bad_bot
SetEnvIfNoCase User-Agent ".*EirGrabber.*" bad_bot
SetEnvIfNoCase User-Agent .*EasyDL.* bad_bot
SetEnvIfNoCase User-Agent ".*Mass\ Downloader.*" bad_bot

# blocking email harvesters
SetEnvIfNoCase User-Agent .*EmailCollector.* bad_bot
SetEnvIfNoCase User-Agent .*EmailSiphon.* bad_bot
SetEnvIfNoCase User-Agent .*EmailWolf.* bad_bot
SetEnvIfNoCase User-Agent .*WebEMailExtrac.* bad_bot

# blocking other crawlers that are causing recursive queries
SetEnvIfNoCase User-Agent .*slurp.* bad_bot           # Yahoo Slurp
SetEnvIfNoCase User-Agent .*MJ12.* bad_bot            # Majestic SEO
SetEnvIfNoCase User-Agent .*FastProbe.* bad_bot       # FastProbe
SetEnvIfNoCase User-Agent .*spbot.* bad_bot           # spBot custom crawler used for internal search engine
SetEnvIfNoCase User-Agent .*dotbot.* bad_bot          # DotBot
SetEnvIfNoCase User-Agent .*semrush.* bad_bot         # SemRush
SetEnvIfNoCase User-Agent .*Daum.* bad_bot            # Daum
SetEnvIfNoCase User-Agent .*AOLBuild.* bad_bot        # AOL
SetEnvIfNoCase User-Agent .*duckduckgo.* bad_bot      # DuckDuckGo
SetEnvIfNoCase User-Agent .*teoma.* bad_bot           # Ask Jeeves

# blocking direct queries via PHP or automated scripts using PHP
SetEnvIfNoCase User-Agent .*PHP\/5.* bad_bot
SetEnvIfNoCase User-Agent .*PHP\/4.* bad_bot
SetEnvIfNoCase User-Agent .*PHP\/3.* bad_bot

# blocking image harvesters and thumbnail generators 
SetEnvIfNoCase User-Agent .*Thumbtack-Thunderdome.* bad_bot
SetEnvIfNoCase User-Agent .*Googlebot-Image.* bad_bot        # yes we block Google Images too due to impact over resources
SetEnvIfNoCase User-Agent .*Googlebot-Video.* bad_bot
SetEnvIfNoCase User-Agent .*bingpreview.* bad_bot
SetEnvIfNoCase User-Agent .*msnbot-media.* bad_bot
SetEnvIfNoCase User-Agent .*Exabot.* bad_bot
SetEnvIfNoCase User-Agent ".*Image\ Stripper.*" bad_bot
SetEnvIfNoCase User-Agent ".*Image\ Sucker.*" bad_bot
SetEnvIfNoCase User-Agent ".*Express\ WebPictures.*" bad_bot

# blocking malicious browsers
SetEnvIfNoCase User-Agent ".*Firefox\ mutant.*" bad_bot
SetEnvIfNoCase User-Agent ".*Ukraine\ Local.*" bad_bot
SetEnvIfNoCase User-Agent ".*Mozilla\/3.Mozilla\/2.01.*" bad_bot
SetEnvIfNoCase User-Agent ".*Mozilla.*NEWT.*" bad_bot

# link extractors
SetEnvIfNoCase User-Agent .*LinkextractorPro.* bad_bot
SetEnvIfNoCase User-Agent ".*LinkScan\/8.1a.Unix.*" bad_bot
SetEnvIfNoCase User-Agent .*LNSpiderguy.* bad_bot
SetEnvIfNoCase User-Agent .*LinkWalker.* bad_bot

# if we do not use the RSS feed or don't want it harvested we can add this too:
SetEnvIfNoCase User-Agent .*feed.* bad_bot
SetEnvIfNoCase User-Agent .*rss.* bad_bot

<Limit GET POST HEAD>
Order Allow,Deny
Allow from all
Deny from env=bad_bot
</Limit>
